<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>BinaryClassifierSupremumBound.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">DROP</a> &gt; <a href="index.source.html" class="el_package">org.drip.sample.classifier</a> &gt; <span class="el_source">BinaryClassifierSupremumBound.java</span></div><h1>BinaryClassifierSupremumBound.java</h1><pre class="source lang-java linenums">
package org.drip.sample.classifier;

import org.drip.learning.rxtor1.*;
import org.drip.numerical.common.FormatUtil;
import org.drip.sequence.functional.FlatMultivariateRandom;
import org.drip.sequence.metrics.SingleSequenceAgnosticMetrics;
import org.drip.sequence.random.*;
import org.drip.service.env.EnvManager;

/*
 * -*- mode: java; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
 */

/*!
 * Copyright (C) 2019 Lakshmi Krishnamurthy
 * Copyright (C) 2018 Lakshmi Krishnamurthy
 * Copyright (C) 2017 Lakshmi Krishnamurthy
 * Copyright (C) 2016 Lakshmi Krishnamurthy
 * Copyright (C) 2015 Lakshmi Krishnamurthy
 * 
 *  This file is part of DROP, an open-source library targeting risk, transaction costs, exposure, margin
 *  	calculations, valuation adjustment, and portfolio construction within and across fixed income,
 *  	credit, commodity, equity, FX, and structured products.
 *  
 *  	https://lakshmidrip.github.io/DROP/
 *  
 *  DROP is composed of three modules:
 *  
 *  - DROP Analytics Core - https://lakshmidrip.github.io/DROP-Analytics-Core/
 *  - DROP Portfolio Core - https://lakshmidrip.github.io/DROP-Portfolio-Core/
 *  - DROP Numerical Core - https://lakshmidrip.github.io/DROP-Numerical-Core/
 * 
 * 	DROP Analytics Core implements libraries for the following:
 * 	- Fixed Income Analytics
 * 	- Asset Backed Analytics
 * 	- XVA Analytics
 * 	- Exposure and Margin Analytics
 * 
 * 	DROP Portfolio Core implements libraries for the following:
 * 	- Asset Allocation Analytics
 * 	- Transaction Cost Analytics
 * 
 * 	DROP Numerical Core implements libraries for the following:
 * 	- Statistical Learning
 * 	- Numerical Optimizer
 * 	- Spline Builder
 * 	- Algorithm Support
 * 
 * 	Documentation for DROP is Spread Over:
 * 
 * 	- Main                     =&gt; https://lakshmidrip.github.io/DROP/
 * 	- Wiki                     =&gt; https://github.com/lakshmiDRIP/DROP/wiki
 * 	- GitHub                   =&gt; https://github.com/lakshmiDRIP/DROP
 * 	- Repo Layout Taxonomy     =&gt; https://github.com/lakshmiDRIP/DROP/blob/master/Taxonomy.md
 * 	- Javadoc                  =&gt; https://lakshmidrip.github.io/DROP/Javadoc/index.html
 * 	- Technical Specifications =&gt; https://github.com/lakshmiDRIP/DROP/tree/master/Docs/Internal
 * 	- Release Versions         =&gt; https://lakshmidrip.github.io/DROP/version.html
 * 	- Community Credits        =&gt; https://lakshmidrip.github.io/DROP/credits.html
 * 	- Issues Catalog           =&gt; https://github.com/lakshmiDRIP/DROP/issues
 * 	- JUnit                    =&gt; https://lakshmidrip.github.io/DROP/junit/index.html
 * 	- Jacoco                   =&gt; https://lakshmidrip.github.io/DROP/jacoco/index.html
 * 
 *  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 *   	you may not use this file except in compliance with the License.
 *   
 *  You may obtain a copy of the License at
 *  	http://www.apache.org/licenses/LICENSE-2.0
 *  
 *  Unless required by applicable law or agreed to in writing, software
 *  	distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 *  	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  
 *  See the License for the specific language governing permissions and
 *  	limitations under the License.
 */

/**
 * &lt;i&gt;BinaryClassifierSupremumBound&lt;/i&gt; demonstrates the Computation of the Probabilistic Bounds for the
 * Supremum among the Class of Binary Classifier Functions for an Empirical Sample from its Population Mean
 * using Variants of the Efron-Stein Methodology.
 *  
 * &lt;br&gt;&lt;br&gt;
 *  &lt;ul&gt;
 *		&lt;li&gt;&lt;b&gt;Module &lt;/b&gt; = &lt;a href = &quot;https://github.com/lakshmiDRIP/DROP/tree/master/NumericalCore.md&quot;&gt;Numerical Core Module&lt;/a&gt;&lt;/li&gt;
 *		&lt;li&gt;&lt;b&gt;Library&lt;/b&gt; = &lt;a href = &quot;https://github.com/lakshmiDRIP/DROP/tree/master/StatisticalLearningLibrary.md&quot;&gt;Statistical Learning Library&lt;/a&gt;&lt;/li&gt;
 *		&lt;li&gt;&lt;b&gt;Project&lt;/b&gt; = &lt;a href = &quot;https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/sample/README.md&quot;&gt;Sample&lt;/a&gt;&lt;/li&gt;
 *		&lt;li&gt;&lt;b&gt;Package&lt;/b&gt; = &lt;a href = &quot;https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/sample/classifier/README.md&quot;&gt;Classifier Agnostic Bounds&lt;/a&gt;&lt;/li&gt;
 *  &lt;/ul&gt;
 * &lt;br&gt;&lt;br&gt;
 *
 * @author Lakshmi Krishnamurthy
 */

<span class="nc" id="L95">public class BinaryClassifierSupremumBound {</span>

	private static final double[] EmpiricalOutcome (
		final int iNumOutcome)
		throws Exception
	{
<span class="nc" id="L101">		double[] adblEmpiricalOutcome = new double[iNumOutcome];</span>

<span class="nc bnc" id="L103" title="All 2 branches missed.">		for (int i = 0; i &lt; iNumOutcome; ++i)</span>
<span class="nc" id="L104">			adblEmpiricalOutcome[i] = Math.random() + 0.5;</span>

<span class="nc" id="L106">		return adblEmpiricalOutcome;</span>
	}

	private static final SingleSequenceAgnosticMetrics[] IIDDraw (
		final UnivariateSequenceGenerator rsg,
		final int iNumSample)
		throws Exception
	{
<span class="nc" id="L114">		SingleSequenceAgnosticMetrics[] aSSAM = new SingleSequenceAgnosticMetrics[iNumSample];</span>

<span class="nc bnc" id="L116" title="All 2 branches missed.">		for (int i = 0; i &lt; iNumSample; ++i)</span>
<span class="nc" id="L117">			aSSAM[i] = rsg.sequence (iNumSample, null);</span>

<span class="nc" id="L119">		return aSSAM;</span>
	}

	private static final EmpiricalPenaltySupremumEstimator EmpiricalLossSupremumFunction (
		final double[] asEmpiricalOutcome)
		throws Exception
	{
		// AbstractBinaryClassifier[] aClassifier = null;

<span class="nc" id="L128">		return null;</span>

		/* return new EmpiricalLossSupremum (
			new GeneralizedClassifierFunctionClass (
				aClassifier,
				new ExpectedSupremumLossAsymptote (
					0.01,
					-1.5
				)
			),
			asEmpiricalOutcome
		); */
	}

	private static final void MartingaleDifferencesRun (
		final Binary bsg,
		final double[] adblEmpiricalOutcome,
		final int iNumSet)
		throws Exception
	{
<span class="nc" id="L148">		String strDump = &quot;\t| &quot; + FormatUtil.FormatDouble (adblEmpiricalOutcome.length, 2, 0, 1.) + &quot; =&gt; &quot;;</span>

<span class="nc bnc" id="L150" title="All 2 branches missed.">		for (int j = 0; j &lt; iNumSet; ++j) {</span>
<span class="nc" id="L151">			SingleSequenceAgnosticMetrics[] aSSAM = IIDDraw (</span>
				bsg,
				adblEmpiricalOutcome.length
			);

<span class="nc" id="L156">			EmpiricalPenaltySupremumMetrics eslm = new EmpiricalPenaltySupremumMetrics (</span>
<span class="nc" id="L157">				EmpiricalLossSupremumFunction (</span>
					adblEmpiricalOutcome
				),
				aSSAM,
				null
			);

<span class="nc bnc" id="L164" title="All 2 branches missed.">			if (0 != j) strDump += &quot; |&quot;;</span>

<span class="nc" id="L166">			strDump += FormatUtil.FormatDouble (eslm.martingaleVarianceUpperBound(), 1, 3, 1.);</span>
		}

<span class="nc" id="L169">		System.out.println (strDump + &quot; |&quot;);</span>
<span class="nc" id="L170">	}</span>

	private static final void GhostVariateVarianceRun (
		final Binary bsg,
		final double[] adblEmpiricalOutcome,
		final int iNumSet)
		throws Exception
	{
<span class="nc" id="L178">		String strDump = &quot;\t| &quot; + FormatUtil.FormatDouble (adblEmpiricalOutcome.length, 2, 0, 1.) + &quot; =&gt; &quot;;</span>

<span class="nc bnc" id="L180" title="All 2 branches missed.">		for (int j = 0; j &lt; iNumSet; ++j) {</span>
<span class="nc" id="L181">			SingleSequenceAgnosticMetrics[] aSSAM = IIDDraw (</span>
				bsg,
				adblEmpiricalOutcome.length
			);

<span class="nc" id="L186">			EmpiricalPenaltySupremumMetrics eslm = new EmpiricalPenaltySupremumMetrics (</span>
<span class="nc" id="L187">				EmpiricalLossSupremumFunction (</span>
					adblEmpiricalOutcome
				),
				aSSAM,
				null
			);

<span class="nc" id="L194">			SingleSequenceAgnosticMetrics[] aSSAMGhost = IIDDraw (</span>
				bsg,
				adblEmpiricalOutcome.length
			);

<span class="nc bnc" id="L199" title="All 2 branches missed.">			if (0 != j) strDump += &quot; |&quot;;</span>

<span class="nc" id="L201">			strDump += FormatUtil.FormatDouble (eslm.ghostVarianceUpperBound (aSSAMGhost), 1, 3, 1.);</span>
		}

<span class="nc" id="L204">		System.out.println (strDump + &quot; |&quot;);</span>
<span class="nc" id="L205">	}</span>

	private static final void EfronSteinSteeleRun (
		final Binary bsg,
		final double[] adblEmpiricalOutcome,
		final int iNumSet)
		throws Exception
	{
<span class="nc" id="L213">		String strDump = &quot;\t| &quot; + FormatUtil.FormatDouble (adblEmpiricalOutcome.length, 2, 0, 1.) + &quot; =&gt; &quot;;</span>

<span class="nc bnc" id="L215" title="All 2 branches missed.">		for (int j = 0; j &lt; iNumSet; ++j) {</span>
<span class="nc" id="L216">			SingleSequenceAgnosticMetrics[] aSSAM = IIDDraw (</span>
				bsg,
				adblEmpiricalOutcome.length
			);

<span class="nc" id="L221">			EmpiricalPenaltySupremumMetrics eslm = new EmpiricalPenaltySupremumMetrics (</span>
<span class="nc" id="L222">				EmpiricalLossSupremumFunction (</span>
					adblEmpiricalOutcome
				),
				aSSAM,
				null
			);

<span class="nc" id="L229">			SingleSequenceAgnosticMetrics[] aSSAMGhost = IIDDraw (</span>
				bsg,
				adblEmpiricalOutcome.length
			);

<span class="nc bnc" id="L234" title="All 2 branches missed.">			if (0 != j) strDump += &quot; |&quot;;</span>

<span class="nc" id="L236">			strDump += FormatUtil.FormatDouble (eslm.efronSteinSteeleBound (aSSAMGhost), 1, 3, 1.);</span>
		}

<span class="nc" id="L239">		System.out.println (strDump + &quot; |&quot;);</span>
<span class="nc" id="L240">	}</span>

	private static final void PivotDifferencesRun (
		final Binary bsg,
		final double[] adblEmpiricalOutcome,
		final int iNumSet)
		throws Exception
	{
<span class="nc" id="L248">		String strDump = &quot;\t| &quot; + FormatUtil.FormatDouble (adblEmpiricalOutcome.length, 2, 0, 1.) + &quot; =&gt; &quot;;</span>

<span class="nc bnc" id="L250" title="All 2 branches missed.">		for (int j = 0; j &lt; iNumSet; ++j) {</span>
<span class="nc" id="L251">			SingleSequenceAgnosticMetrics[] aSSAM = IIDDraw (</span>
				bsg,
				adblEmpiricalOutcome.length
			);

<span class="nc" id="L256">			EmpiricalPenaltySupremumMetrics eslm = new EmpiricalPenaltySupremumMetrics (</span>
<span class="nc" id="L257">				EmpiricalLossSupremumFunction (</span>
					adblEmpiricalOutcome
				),
				aSSAM,
				null
			);

<span class="nc bnc" id="L264" title="All 2 branches missed.">			if (0 != j) strDump += &quot; |&quot;;</span>

<span class="nc" id="L266">			strDump += FormatUtil.FormatDouble (eslm.pivotVarianceUpperBound (new FlatMultivariateRandom (0.)), 1, 3, 1.);</span>
		}

<span class="nc" id="L269">		System.out.println (strDump + &quot; |&quot;);</span>
<span class="nc" id="L270">	}</span>

	private static final void LugosiVarianceRun (
		final Binary bsg,
		final double[] adblEmpiricalOutcome,
		final int iNumSet)
		throws Exception
	{
<span class="nc" id="L278">		String strDump = &quot;\t| &quot; + FormatUtil.FormatDouble (adblEmpiricalOutcome.length, 2, 0, 1.) + &quot; =&gt; &quot;;</span>

<span class="nc bnc" id="L280" title="All 2 branches missed.">		for (int j = 0; j &lt; iNumSet; ++j) {</span>
<span class="nc" id="L281">			SingleSequenceAgnosticMetrics[] aSSAM = IIDDraw (</span>
				bsg,
				adblEmpiricalOutcome.length
			);

<span class="nc" id="L286">			EmpiricalPenaltySupremumMetrics eslm = new EmpiricalPenaltySupremumMetrics (</span>
<span class="nc" id="L287">				EmpiricalLossSupremumFunction (</span>
					adblEmpiricalOutcome
				),
				aSSAM,
				null
			);

<span class="nc" id="L294">			SingleSequenceAgnosticMetrics[] aSSAMGhost = IIDDraw (</span>
				bsg,
				1
			);

<span class="nc bnc" id="L299" title="All 2 branches missed.">			if (0 != j) strDump += &quot; |&quot;;</span>

<span class="nc" id="L301">			strDump += FormatUtil.FormatDouble (eslm.lugosiVarianceBound (aSSAMGhost[0].sequence()), 1, 3, 1.);</span>
		}

<span class="nc" id="L304">		System.out.println (strDump + &quot; |&quot;);</span>
<span class="nc" id="L305">	}</span>

	public static final void main (
		final String[] astrArgs)
		throws Exception
	{
<span class="nc" id="L311">		EnvManager.InitEnv (&quot;&quot;);</span>

<span class="nc" id="L313">		int iNumSet = 5;</span>

<span class="nc" id="L315">		int[] aiSampleSize = new int[] {</span>
			3, 10, 25, 50
		};

<span class="nc" id="L319">		Binary bin = new Binary (0.7);</span>

<span class="nc" id="L321">		System.out.println (&quot;\n\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L323">		System.out.println (&quot;\t|  Martingale Differences Variance Upper Bound  |&quot;);</span>

<span class="nc" id="L325">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc bnc" id="L327" title="All 2 branches missed.">		for (int iSampleSize : aiSampleSize)</span>
<span class="nc" id="L328">			MartingaleDifferencesRun (</span>
				bin,
<span class="nc" id="L330">				EmpiricalOutcome (iSampleSize),</span>
				iNumSet
			);

<span class="nc" id="L334">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L336">		System.out.println (&quot;\n\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L338">		System.out.println (&quot;\t|   Symmetrized Variate Variance Upper Bound    |&quot;);</span>

<span class="nc" id="L340">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc bnc" id="L342" title="All 2 branches missed.">		for (int iSampleSize : aiSampleSize)</span>
<span class="nc" id="L343">			GhostVariateVarianceRun (</span>
				bin,
<span class="nc" id="L345">				EmpiricalOutcome (iSampleSize),</span>
				iNumSet
			);

<span class="nc" id="L349">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L351">		aiSampleSize = new int[] {</span>
			3, 10, 25, 50, 75, 99
		};

<span class="nc" id="L355">		System.out.println (&quot;\t|    Efron-Stein-Steele Variance Upper Bound    |&quot;);</span>

<span class="nc" id="L357">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc bnc" id="L359" title="All 2 branches missed.">		for (int iSampleSize : aiSampleSize)</span>
<span class="nc" id="L360">			EfronSteinSteeleRun (</span>
				bin,
<span class="nc" id="L362">				EmpiricalOutcome (iSampleSize),</span>
				iNumSet
			);

<span class="nc" id="L366">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L368">		System.out.println (&quot;\n\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L370">		System.out.println (&quot;\t|    Pivoted Differences Variance Upper Bound   |&quot;);</span>

<span class="nc" id="L372">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc bnc" id="L374" title="All 2 branches missed.">		for (int iSampleSize : aiSampleSize)</span>
<span class="nc" id="L375">			PivotDifferencesRun (</span>
				bin,
<span class="nc" id="L377">				EmpiricalOutcome (iSampleSize),</span>
				iNumSet
			);

<span class="nc" id="L381">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L383">		System.out.println (&quot;\n\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L385">		System.out.println (&quot;\t|       Lugosi Bounded Variance Upper Bound       |&quot;);</span>

<span class="nc" id="L387">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc bnc" id="L389" title="All 2 branches missed.">		for (int iSampleSize : aiSampleSize)</span>
<span class="nc" id="L390">			LugosiVarianceRun (</span>
				bin,
<span class="nc" id="L392">				EmpiricalOutcome (iSampleSize),</span>
				iNumSet
			);

<span class="nc" id="L396">		System.out.println (&quot;\t|-----------------------------------------------|&quot;);</span>

<span class="nc" id="L398">		EnvManager.TerminateEnv();</span>
<span class="nc" id="L399">	}</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.9.201702052155</span></div></body></html>