<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>RdDecisionFunction.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">DROP</a> &gt; <a href="index.source.html" class="el_package">org.drip.learning.svm</a> &gt; <span class="el_source">RdDecisionFunction.java</span></div><h1>RdDecisionFunction.java</h1><pre class="source lang-java linenums">
package org.drip.learning.svm;

/*
 * -*- mode: java; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*-
 */


/*!
 * Copyright (C) 2019 Lakshmi Krishnamurthy
 * Copyright (C) 2018 Lakshmi Krishnamurthy
 * Copyright (C) 2017 Lakshmi Krishnamurthy
 * Copyright (C) 2016 Lakshmi Krishnamurthy
 * Copyright (C) 2015 Lakshmi Krishnamurthy
 * 
 *  This file is part of DROP, an open-source library targeting risk, transaction costs, exposure, margin
 *  	calculations, and portfolio construction within and across fixed income, credit, commodity, equity,
 *  	FX, and structured products.
 *  
 *  	https://lakshmidrip.github.io/DROP/
 *  
 *  DROP is composed of three main modules:
 *  
 *  - DROP Analytics Core - https://lakshmidrip.github.io/DROP-Analytics-Core/
 *  - DROP Portfolio Core - https://lakshmidrip.github.io/DROP-Portfolio-Core/
 *  - DROP Numerical Core - https://lakshmidrip.github.io/DROP-Numerical-Core/
 * 
 * 	DROP Analytics Core implements libraries for the following:
 * 	- Fixed Income Analytics
 * 	- Asset Backed Analytics
 * 	- XVA Analytics
 * 	- Exposure and Margin Analytics
 * 
 * 	DROP Portfolio Core implements libraries for the following:
 * 	- Asset Allocation Analytics
 * 	- Transaction Cost Analytics
 * 
 * 	DROP Numerical Core implements libraries for the following:
 * 	- Statistical Learning Library
 * 	- Numerical Optimizer Library
 * 	- Machine Learning Library
 * 	- Spline Builder Library
 * 
 * 	Documentation for DROP is Spread Over:
 * 
 * 	- Main                     =&gt; https://lakshmidrip.github.io/DROP/
 * 	- Wiki                     =&gt; https://github.com/lakshmiDRIP/DROP/wiki
 * 	- GitHub                   =&gt; https://github.com/lakshmiDRIP/DROP
 * 	- Javadoc                  =&gt; https://lakshmidrip.github.io/DROP/Javadoc/index.html
 * 	- Technical Specifications =&gt; https://github.com/lakshmiDRIP/DROP/tree/master/Docs/Internal
 * 	- Release Versions         =&gt; https://lakshmidrip.github.io/DROP/version.html
 * 	- Community Credits        =&gt; https://lakshmidrip.github.io/DROP/credits.html
 * 	- Issues Catalog           =&gt; https://github.com/lakshmiDRIP/DROP/issues
 * 	- JUnit                    =&gt; https://lakshmidrip.github.io/DROP/junit/index.html
 * 	- Jacoco                   =&gt; https://lakshmidrip.github.io/DROP/jacoco/index.html
 * 
 *  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 *   	you may not use this file except in compliance with the License.
 *   
 *  You may obtain a copy of the License at
 *  	http://www.apache.org/licenses/LICENSE-2.0
 *  
 *  Unless required by applicable law or agreed to in writing, software
 *  	distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 *  	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  
 *  See the License for the specific language governing permissions and
 *  	limitations under the License.
 */

/**
 * &lt;i&gt;RdDecisionFunction&lt;/i&gt; exposes the R&lt;sup&gt;d&lt;/sup&gt; Decision-Function Based SVM Functionality for
 * Classification and Regression.
 * 
 * &lt;br&gt;&lt;br&gt;
 *  The References are:
 * &lt;br&gt;&lt;br&gt;
 * &lt;ul&gt;
 * 	&lt;li&gt;
 * 		Shawe-Taylor, J., P. L. Bartlett, R. C. Williamson, and M. Anthony (1996): A Framework for Structural
 * 			Risk Minimization, in: &lt;i&gt;Proceedings of the 9th Annual Conference on Computational Learning
 * 			Theory&lt;/i&gt; &lt;b&gt;ACM&lt;/b&gt; New York 68-76
 * 	&lt;/li&gt;
 * 	&lt;li&gt;
 * 		Vapnik, V., and A. Chervonenkis (1974): &lt;i&gt;Theory of Pattern Recognition (in Russian)&lt;/i&gt;
 * 			&lt;b&gt;Nauka&lt;/b&gt; Moscow USSR
 * 	&lt;/li&gt;
 * 	&lt;li&gt;
 * 		Vapnik, V. (1995): &lt;i&gt;The Nature of Statistical Learning&lt;/i&gt; &lt;b&gt;Springer-Verlag&lt;/b&gt; New York
 * 	&lt;/li&gt;
 * &lt;/ul&gt;
 * 
 * &lt;br&gt;&lt;br&gt;
 *  &lt;ul&gt;
 *		&lt;li&gt;&lt;b&gt;Module&lt;/b&gt;        = &lt;a href = &quot;https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/learning&quot;&gt;Learning&lt;/a&gt;&lt;/li&gt;
 *		&lt;li&gt;&lt;b&gt;Package&lt;/b&gt;       = &lt;a href = &quot;https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/learning/svm&quot;&gt;Support Vector Machines&lt;/a&gt;&lt;/li&gt;
 *		&lt;li&gt;&lt;b&gt;Specification&lt;/b&gt; = &lt;a href = &quot;https://github.com/lakshmiDRIP/DROP/tree/master/Docs/Internal/StatisticalLearning&quot;&gt;Statistical Learning Library&lt;/a&gt;&lt;/li&gt;
 *  &lt;/ul&gt;
 * &lt;br&gt;&lt;br&gt;
 *
 * @author Lakshmi Krishnamurthy
 */

public abstract class RdDecisionFunction extends org.drip.function.definition.RdToR1 {
<span class="nc" id="L105">	private double _dblB = java.lang.Double.NaN;</span>
<span class="nc" id="L106">	private double[] _adblInverseMarginWeight = null;</span>
<span class="nc" id="L107">	private org.drip.spaces.metric.RdNormed _rdInverseMargin = null;</span>
<span class="nc" id="L108">	private org.drip.spaces.tensor.RdGeneralizedVector _rdPredictor = null;</span>

	/**
	 * RdDecisionFunction Constructor
	 * 
	 * @param rdPredictor The R^d Metric Input Predictor Space
	 * @param rdInverseMargin The Inverse Margin Weights R^d Space
	 * @param adblInverseMarginWeight Array of Inverse Margin Weights
	 * @param dblB The Kernel Offset
	 * 
	 * @throws java.lang.Exception Thrown if the Inputs are Invalid
	 */

	public RdDecisionFunction (
		final org.drip.spaces.tensor.RdGeneralizedVector rdPredictor,
		final org.drip.spaces.metric.RdNormed rdInverseMargin,
		final double[] adblInverseMarginWeight,
		final double dblB)
		throws java.lang.Exception
	{
<span class="nc" id="L128">		super (null);</span>

<span class="nc bnc" id="L130" title="All 6 branches missed.">		if (null == (_rdPredictor = rdPredictor) || null == (_rdInverseMargin = rdInverseMargin) || null ==</span>
			(_adblInverseMarginWeight = adblInverseMarginWeight) || !org.drip.quant.common.NumberUtil.IsValid
<span class="nc bnc" id="L132" title="All 2 branches missed.">				(_dblB = dblB))</span>
<span class="nc" id="L133">			throw new java.lang.Exception (&quot;RdDecisionFunction ctr: Invalid Inputs&quot;);</span>

<span class="nc" id="L135">		int iNumMarginWeight = _adblInverseMarginWeight.length;</span>

<span class="nc bnc" id="L137" title="All 4 branches missed.">		if (0 == iNumMarginWeight || iNumMarginWeight != _rdPredictor.dimension())</span>
<span class="nc" id="L138">			throw new java.lang.Exception (&quot;RdDecisionFunction ctr: Invalid Inputs&quot;);</span>
<span class="nc" id="L139">	}</span>

	/**
	 * Retrieve the Input Predictor Metric Vector Space
	 * 
	 * @return The Input Predictor Metric Vector Space
	 */

	public org.drip.spaces.tensor.RdGeneralizedVector predictorSpace()
	{
<span class="nc" id="L149">		return _rdPredictor;</span>
	}

	/**
	 * Retrieve the Inverse Margin Weight Metric Vector Space
	 * 
	 * @return The Inverse Margin Weight Metric Vector Space
	 */

	public org.drip.spaces.metric.RdNormed inverseMarginSpace()
	{
<span class="nc" id="L160">		return _rdInverseMargin;</span>
	}

	/**
	 * Retrieve the Decision Kernel Weights
	 * 
	 * @return The Decision Kernel Weights
	 */

	public double[] inverseMarginWeights()
	{
<span class="nc" id="L171">		return _adblInverseMarginWeight;</span>
	}

	/**
	 * Retrieve the Offset
	 * 
	 * @return The Offset
	 */

	public double offset()
	{
<span class="nc" id="L182">		return _dblB;</span>
	}

	/**
	 * Classify the Specified Multi-dimensional Point
	 * 
	 * @param adblX The Multi-dimensional Input Point
	 * 
	 * @return +1/-1 Boolean Space Output Equivalents
	 * 
	 * @throws java.lang.Exception Thrown if the Inputs are Invalid
	 */

	public short classify (
		final double[] adblX)
		throws java.lang.Exception
	{
<span class="nc bnc" id="L199" title="All 2 branches missed.">		return evaluate (adblX) &gt; 0. ? org.drip.spaces.tensor.BinaryBooleanVector.BBV_UP :</span>
			org.drip.spaces.tensor.BinaryBooleanVector.BBV_DOWN;
	}

	/**
	 * Regress on the Specified Multi-dimensional Point
	 * 
	 * @param adblX The Multi-dimensional Input Point
	 * 
	 * @return The Regression Output
	 * 
	 * @throws java.lang.Exception Thrown if the Inputs are Invalid
	 */

	public double regress (
		final double[] adblX)
		throws java.lang.Exception
	{
<span class="nc" id="L217">		return evaluate (adblX);</span>
	}

	/**
	 * Compute the Entropy Number Upper Bounds Instance for the Specified Inputs
	 * 
	 * @param dsoFactorizer The Factorizing Diagonal Scaling Operator
	 * @param dblFeatureSpaceMaureyConstant The Feature Space Maurey Constant
	 * 
	 * @return The Entropy Number Upper Bounds Instance
	 */

	public org.drip.learning.svm.DecisionFunctionOperatorBounds entropyNumberUpperBounds (
		final org.drip.learning.kernel.DiagonalScalingOperator dsoFactorizer,
		final double dblFeatureSpaceMaureyConstant)
	{
		try {
<span class="nc" id="L234">			return new org.drip.learning.svm.DecisionFunctionOperatorBounds (dsoFactorizer,</span>
<span class="nc" id="L235">				inverseMarginSpace().populationMetricNorm(), dblFeatureSpaceMaureyConstant,</span>
<span class="nc" id="L236">					predictorSpace().dimension());</span>
<span class="nc" id="L237">		} catch (java.lang.Exception e) {</span>
<span class="nc" id="L238">			e.printStackTrace();</span>
		}

<span class="nc" id="L241">		return null;</span>
	}

	/**
	 * Compute the Decision Function's Asymptotic Exponent for the Entropy Number
	 * 
	 * @param dsoFactorizer The Factorizing Diagonal Scaling Operator
	 * 
	 * @return The Decision Function's Asymptotic Exponent for the Entropy Number
	 * 
	 * @throws java.lang.Exception Thrown if the Asymptotoc Exponent cannot be computed
	 */

	public double logEntropyNumberAsymptote (
		final org.drip.learning.kernel.DiagonalScalingOperator dsoFactorizer)
		throws java.lang.Exception
	{
<span class="nc bnc" id="L258" title="All 2 branches missed.">		if (null == dsoFactorizer)</span>
<span class="nc" id="L259">			throw new java.lang.Exception</span>
				(&quot;RdDecisionFunction::logEntropyNumberAsymptote =&gt; Invalid Inputs&quot;);

<span class="nc" id="L262">		org.drip.learning.bound.DiagonalOperatorCoveringBound docb = dsoFactorizer.entropyNumberAsymptote();</span>

<span class="nc bnc" id="L264" title="All 2 branches missed.">		if (null == docb)</span>
<span class="nc" id="L265">			throw new java.lang.Exception</span>
				(&quot;RdDecisionFunction::logEntropyNumberAsymptote =&gt; Cannot get Diagonal Operator Covering Bounds&quot;);

<span class="nc" id="L268">		return org.drip.learning.bound.DiagonalOperatorCoveringBound.BASE_DIAGONAL_ENTROPY_ASYMPTOTE_EXPONENT</span>
<span class="nc bnc" id="L269" title="All 2 branches missed.">			== docb.entropyNumberAsymptoteType() ? -1. * docb.entropyNumberAsymptoteExponent() - 0.5 :</span>
<span class="nc" id="L270">				-1. * docb.entropyNumberAsymptoteExponent();</span>
	}

	/**
	 * Optimize the Hyper-plane for the Purposes of Regression
	 * 
	 * @param adblEmpirical The Empirical Observation Array
	 * @param dblMargin The Optimization Margin
	 * @param dblInverseWidthNormConstraint The Inverse Width Norm Constraint
	 * 
	 * @return TRUE - The Hyper-plane has been successfully Optimized for Regression
	 */

	public abstract boolean optimizeRegressionHyperplane (
		final double[] adblEmpirical,
		final double dblMargin,
		final double dblInverseWidthNormConstraint
	);

	/**
	 * Optimize the Hyper-plane for the Purposes of Classification
	 * 
	 * @param asEmpirical The Empirical Observation Array
	 * @param dblMargin The Optimization Margin
	 * @param dblInverseWidthNormConstraint The Inverse Width Norm Constraint
	 * 
	 * @return TRUE - The Hyper-plane has been successfully Optimized for Classification
	 */

	public abstract boolean optimizeClassificationHyperplane (
		final short[] asEmpirical,
		final double dblMargin,
		final double dblInverseWidthNormConstraint
	);
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.9.201702052155</span></div></body></html>